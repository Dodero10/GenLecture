{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Tải tokenizer và mô hình\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-1.5B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in d:\\github\\genlecture\\env_l2s\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets\n",
    "!conda install -c conda-forge ipywidgets\n",
    "!pip install --upgrade notebook\n",
    "!conda update notebook\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\github\\GenLecture\\env_l2s\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Both `max_new_tokens` (=2048) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giới thiệu về học máy và các ứng dụng thực tiễn. - Trang 2\n",
      "Giới thiệu về học máy và các ứng dụng thực tiễn.\n",
      "Thứ 2, 11:00, 18/03/2018\n",
      "Giới thiệu về học máy và các ứng dụng thực tiễn.\n",
      "Học máy là một lĩnh vực nghiên cứu và phát triển các phương pháp, công nghệ, thiết bị, quy trình, phương pháp để giải quyết các vấn đề về máy tính, xử lý thông tin, xử lý dữ liệu, xử lý ngôn ngữ, xử lý hình ảnh, xử lý video, xử lý âm thanh, xử lý ngôn ngữ tự nhiên, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy tính, xử lý ngôn ngữ máy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Tải tokenizer và mô hình\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-1.5B\")\n",
    "\n",
    "# Đảm bảo mô hình chạy trên CPU\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Hàm sinh văn bản từ prompt\n",
    "def generate_text(prompt, max_length=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs.input_ids, max_length=max_length, temperature=0.7)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "prompt = \"Giới thiệu về học máy và các ứng dụng thực tiễn.\"\n",
    "generated_script = generate_text(prompt)\n",
    "print(generated_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
